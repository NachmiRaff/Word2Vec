{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c96c18-a0b1-4be8-9c99-48803141fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "files = ['old/Slate star codex.txt', 'old/2020.txt', 'old/2021.txt', 'old/2022.txt', 'old/2023.txt', 'old/2024.txt', 'old/2025.txt']\n",
    "\n",
    "content = bytes()\n",
    "for file in files:\n",
    "    with open(file, 'rb') as f:\n",
    "        content += f.read()\n",
    "        \n",
    "content = [i for i in re.sub(r'[^a-zA-Z ]+', ' ', content.decode(\"utf-8\")).lower().split(\" \") if i != '']\n",
    "\n",
    "words = defaultdict(int)\n",
    "for s in content:\n",
    "    words[s] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325285f9-26bc-4f54-a949-e62071740dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "content  = [i for i in content if words[i] >=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb40f03-6e8a-47b3-8e2f-21a54a91cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [i for i, j in words.items() if j>=100]\n",
    "vocab.sort()\n",
    "size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a16a73-b38d-4adb-85cc-761c0aecee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content length is 6936885 words long\n",
      "vocab size is 5686\n"
     ]
    }
   ],
   "source": [
    "print('content length is', len(content),'words long\\nvocab size is', size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d37ef9-f611-4bf0-9ad0-e1f60fd2ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_num = {}\n",
    "for i,w in enumerate(vocab):\n",
    "    word_num[w] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48ab4f7-2ece-4442-b1b8-8494c8510790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nVec(x):\n",
    "    v = np.zeros(size)\n",
    "    v[x] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c4b0b9-c6a3-4d94-a844-572500acfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "window = 8\n",
    "for i,w in enumerate(content):\n",
    "    if(i>window and i+window<len(content)):\n",
    "        train.append((w,content[i-window//2:i]+content[i+1:i+window//2+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7744faf-c9aa-4b74-bd0b-8d745271d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vector):\n",
    "    e = np.exp(vector - np.max(vector))\n",
    "    return e/np.sum(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17bd4960-9049-48fe-aa2e-c82d17909111",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = 200\n",
    "W1 = np.random.randn(size, embedding)\n",
    "W2 = np.random.randn(embedding, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf48154-f8e0-4d22-b248-99a1c4b6ca93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main table of contents slate star codex slate star codex slate star codex slate star codex slate star codex slate star codex slate star codex slate star codex slate star codex written by scott alexander table of contents you re probably wondering why i ve called you here today lincoln you cannot serve both god and but you can serve by predicting who will serve god google correlate does not imply google causation of all claims about the problems with medical studies are wrong typical mind and gender identity i liked before it was cool future a defense of logical yes really and discourse third edition the continues links for february people it turns out capitalism is actually a thing s last stand coordination thread launch day pope and change an atheist "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for word, data in train:\n",
    "        index = word_num[word]\n",
    "        nVec = get_nVec(index)\n",
    "        hidden = np.dot(nVec, W1)\n",
    "        out = np.dot(hidden, W2)\n",
    "        chance = softmax(out)\n",
    "\n",
    "        data_num = [word_num[i] for i in data]\n",
    "        loss -= np.sum(np.log(chance[data_num]))\n",
    "        \n",
    "        #AI code\n",
    "        grad_W2_accum = np.zeros_like(W2)  # Initialize accumulated gradient for W2\n",
    "        grad_W1_accum = np.zeros_like(W1)  # Initialize accumulated gradient for W1\n",
    "\n",
    "        for context_word in data:            \n",
    "            # Compute the gradients for the context word\n",
    "            grad_out = chance - get_nVec(word_num[context_word])\n",
    "            grad_W2_accum += np.outer(hidden, grad_out)  # Accumulate gradient for W2\n",
    "            \n",
    "            grad_hidden = np.dot(W2, grad_out)  # Backpropagate to hidden layer\n",
    "            index = word_num[word]  # Index of the current input word\n",
    "            grad_W1_accum[index] += grad_hidden  # Update only that specific row\n",
    "    \n",
    "           # Update W1 and W2 after summing gradients from all context words\n",
    "        lr = 0.01  # Learning rate\n",
    "        W1 -= lr * grad_W1_accum\n",
    "        W2 -= lr * grad_W2_accum\n",
    "        \n",
    "        print(word, end = \" \")\n",
    "\n",
    "    print('epoch', epoch, 'finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb134f7-acb5-4cd0-8bd8-b1a20465a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "session_filename = \"encoderTry1.dill\"\n",
    "dill.dump_session(session_filename)\n",
    "print(f\"Jupyter Notebook session saved to '{session_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4911841-c563-4a9e-8ba8-e2f1f916b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b05dbd-13d5-4116-a3c4-f54c70d6c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "session_filename = \"jupyter_session.dill\"\n",
    "\n",
    "try:\n",
    "    dill.load_session(session_filename)\n",
    "    print(f\"Jupyter Notebook session loaded from '{session_filename}'\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{session_filename}' not found. Starting with a fresh session.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading session: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07897f3-ab6f-4adc-b6df-41a9e7b6c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9a446-4406-4020-a870-1cf38dc84b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
